{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('../Cluster1Mondayn.csv', index_col='Time', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data.drop(['dayofyear', 'month', 'dayofweek', 'hourofday', 'minuteofday', 'daytype', 'season'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, Y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        \n",
    "        end_ix = i + n_steps\n",
    "        \n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x) \n",
    "        Y.append(seq_y)\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "n_steps = 3\n",
    "X, Y = split_sequence(data.values, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 3, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Energy_Series(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        y = self.targets[idx]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, 1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(64, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv2(self.relu(self.conv1(x))))\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 64)\n",
    "        x = self.fc2(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "a = CNN()\n",
    "out = a(torch.randn(2, 3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1d = nn.Conv1d(3,64,kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(64*2,50)\n",
    "        self.fc2 = nn.Linear(50,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = CNN().to(device).double()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Energy_Series(X.reshape(X.shape[0],X.shape[1],1),Y)\n",
    "train_loader = torch.utils.data.DataLoader(train,batch_size=2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "def Train():\n",
    "    running_loss = 0\n",
    "    \n",
    "    model.train() \n",
    "    \n",
    "    for idx, (inputs,labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs.double())\n",
    "        loss = criterion(preds,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        \n",
    "    train_loss = running_loss/len(train_loader)\n",
    "    train_losses.append(train_loss.detach().numpy())\n",
    "    \n",
    "    print(f'train_loss {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1/500\n",
      "train_loss 0.006685683747523306\n",
      "epochs 2/500\n",
      "train_loss 0.001553065696237683\n",
      "epochs 3/500\n",
      "train_loss 0.0015317401447837871\n",
      "epochs 4/500\n",
      "train_loss 0.0015409628178914099\n",
      "epochs 5/500\n",
      "train_loss 0.001508830754670187\n",
      "epochs 6/500\n",
      "train_loss 0.0014723433584064758\n",
      "epochs 7/500\n",
      "train_loss 0.0014293558628704027\n",
      "epochs 8/500\n",
      "train_loss 0.0013898625451753467\n",
      "epochs 9/500\n",
      "train_loss 0.0013523853879581088\n",
      "epochs 10/500\n",
      "train_loss 0.0013200077310796627\n",
      "epochs 11/500\n",
      "train_loss 0.0012917495276335226\n",
      "epochs 12/500\n",
      "train_loss 0.0012670664858815612\n",
      "epochs 13/500\n",
      "train_loss 0.001242809983747764\n",
      "epochs 14/500\n",
      "train_loss 0.0012192759679507785\n",
      "epochs 15/500\n",
      "train_loss 0.0011978771106214109\n",
      "epochs 16/500\n",
      "train_loss 0.0011785342689516745\n",
      "epochs 17/500\n",
      "train_loss 0.0011600158801451286\n",
      "epochs 18/500\n",
      "train_loss 0.0011433028856360058\n",
      "epochs 19/500\n",
      "train_loss 0.0011268946279712395\n",
      "epochs 20/500\n",
      "train_loss 0.0011074820014544586\n",
      "epochs 21/500\n",
      "train_loss 0.0010970089439547455\n",
      "epochs 22/500\n",
      "train_loss 0.0010847887272884573\n",
      "epochs 23/500\n",
      "train_loss 0.0010711802877448292\n",
      "epochs 24/500\n",
      "train_loss 0.0010609800168586833\n",
      "epochs 25/500\n",
      "train_loss 0.0010485627212292036\n",
      "epochs 26/500\n",
      "train_loss 0.0010388393773264671\n",
      "epochs 27/500\n",
      "train_loss 0.001027586914362141\n",
      "epochs 28/500\n",
      "train_loss 0.0010204508863173002\n",
      "epochs 29/500\n",
      "train_loss 0.0010101273167306148\n",
      "epochs 30/500\n",
      "train_loss 0.0010012346345207445\n",
      "epochs 31/500\n",
      "train_loss 0.000993520879368848\n",
      "epochs 32/500\n",
      "train_loss 0.0009808455956024683\n",
      "epochs 33/500\n",
      "train_loss 0.0009849955283651555\n",
      "epochs 34/500\n",
      "train_loss 0.00096910024327269\n",
      "epochs 35/500\n",
      "train_loss 0.0009572202171129996\n",
      "epochs 36/500\n",
      "train_loss 0.0009522666936878566\n",
      "epochs 37/500\n",
      "train_loss 0.000943115322217579\n",
      "epochs 38/500\n",
      "train_loss 0.0009376102890344954\n",
      "epochs 39/500\n",
      "train_loss 0.0009299538468172775\n",
      "epochs 40/500\n",
      "train_loss 0.0009267607745775125\n",
      "epochs 41/500\n",
      "train_loss 0.0009193262702117202\n",
      "epochs 42/500\n",
      "train_loss 0.0009153016088267386\n",
      "epochs 43/500\n",
      "train_loss 0.0009068554712223201\n",
      "epochs 44/500\n",
      "train_loss 0.0009036390642692676\n",
      "epochs 45/500\n",
      "train_loss 0.0008967132418831915\n",
      "epochs 46/500\n",
      "train_loss 0.0008933553041446698\n",
      "epochs 47/500\n",
      "train_loss 0.0008884363639595897\n",
      "epochs 48/500\n",
      "train_loss 0.0008813503673923464\n",
      "epochs 49/500\n",
      "train_loss 0.00087932615585533\n",
      "epochs 50/500\n",
      "train_loss 0.000873607501574702\n",
      "epochs 51/500\n",
      "train_loss 0.0008728467119226685\n",
      "epochs 52/500\n",
      "train_loss 0.0008661786881473791\n",
      "epochs 53/500\n",
      "train_loss 0.0008587892786147884\n",
      "epochs 54/500\n",
      "train_loss 0.0008571134540791125\n",
      "epochs 55/500\n",
      "train_loss 0.0008507297145275475\n",
      "epochs 56/500\n",
      "train_loss 0.0008516232991158927\n",
      "epochs 57/500\n",
      "train_loss 0.0008450351566132967\n",
      "epochs 58/500\n",
      "train_loss 0.0008418514399457954\n",
      "epochs 59/500\n",
      "train_loss 0.0008392830919106886\n",
      "epochs 60/500\n",
      "train_loss 0.0008350967922503093\n",
      "epochs 61/500\n",
      "train_loss 0.0008351154893464165\n",
      "epochs 62/500\n",
      "train_loss 0.0008291236823599102\n",
      "epochs 63/500\n",
      "train_loss 0.0008289512064669985\n",
      "epochs 64/500\n",
      "train_loss 0.0008219117321525982\n",
      "epochs 65/500\n",
      "train_loss 0.0008214019717104668\n",
      "epochs 66/500\n",
      "train_loss 0.0008195801605155017\n",
      "epochs 67/500\n",
      "train_loss 0.0008148986854301024\n",
      "epochs 68/500\n",
      "train_loss 0.0008131431749987532\n",
      "epochs 69/500\n",
      "train_loss 0.0008108546070688166\n",
      "epochs 70/500\n",
      "train_loss 0.0008083248072213407\n",
      "epochs 71/500\n",
      "train_loss 0.0008032195417831624\n",
      "epochs 72/500\n",
      "train_loss 0.0008065855289397667\n",
      "epochs 73/500\n",
      "train_loss 0.0008015635295366614\n",
      "epochs 74/500\n",
      "train_loss 0.0008026429348354876\n",
      "epochs 75/500\n",
      "train_loss 0.0007979465198974043\n",
      "epochs 76/500\n",
      "train_loss 0.0007911752121427275\n",
      "epochs 77/500\n",
      "train_loss 0.0007945068227756776\n",
      "epochs 78/500\n",
      "train_loss 0.0007918324318043547\n",
      "epochs 79/500\n",
      "train_loss 0.0007912549462017937\n",
      "epochs 80/500\n",
      "train_loss 0.0007922964828171514\n",
      "epochs 81/500\n",
      "train_loss 0.0007837014699020546\n",
      "epochs 82/500\n",
      "train_loss 0.0007860907823420326\n",
      "epochs 83/500\n",
      "train_loss 0.0007835850504179395\n",
      "epochs 84/500\n",
      "train_loss 0.0007829187606492175\n",
      "epochs 85/500\n",
      "train_loss 0.0007784992186517309\n",
      "epochs 86/500\n",
      "train_loss 0.0007829829943561645\n",
      "epochs 87/500\n",
      "train_loss 0.0007744536195625337\n",
      "epochs 88/500\n",
      "train_loss 0.0007823882750633466\n",
      "epochs 89/500\n",
      "train_loss 0.0007703613929889859\n",
      "epochs 90/500\n",
      "train_loss 0.0007746395381665808\n",
      "epochs 91/500\n",
      "train_loss 0.0007687458987701875\n",
      "epochs 92/500\n",
      "train_loss 0.000773939428859913\n",
      "epochs 93/500\n",
      "train_loss 0.0007660442787757561\n",
      "epochs 94/500\n",
      "train_loss 0.0007671951382029368\n",
      "epochs 95/500\n",
      "train_loss 0.0007668018044524159\n",
      "epochs 96/500\n",
      "train_loss 0.0007643116471964858\n",
      "epochs 97/500\n",
      "train_loss 0.0007661645108299586\n",
      "epochs 98/500\n",
      "train_loss 0.0007579394638781791\n",
      "epochs 99/500\n",
      "train_loss 0.0007610967647134401\n",
      "epochs 100/500\n",
      "train_loss 0.0007587919793181631\n",
      "epochs 101/500\n",
      "train_loss 0.0007626095772201433\n",
      "epochs 102/500\n",
      "train_loss 0.0007573977032935578\n",
      "epochs 103/500\n",
      "train_loss 0.0007560738675365308\n",
      "epochs 104/500\n",
      "train_loss 0.0007528121754877933\n",
      "epochs 105/500\n",
      "train_loss 0.0007571867635531917\n",
      "epochs 106/500\n",
      "train_loss 0.0007497253115693561\n",
      "epochs 107/500\n",
      "train_loss 0.0007532439959197188\n",
      "epochs 108/500\n",
      "train_loss 0.0007497702878769023\n",
      "epochs 109/500\n",
      "train_loss 0.0007547828831296971\n",
      "epochs 110/500\n",
      "train_loss 0.000748570911206771\n",
      "epochs 111/500\n",
      "train_loss 0.0007496628250356388\n",
      "epochs 112/500\n",
      "train_loss 0.0007460062521636264\n",
      "epochs 113/500\n",
      "train_loss 0.0007507828717039295\n",
      "epochs 114/500\n",
      "train_loss 0.0007439053090154588\n",
      "epochs 115/500\n",
      "train_loss 0.0007472866973943426\n",
      "epochs 116/500\n",
      "train_loss 0.000742953500848674\n",
      "epochs 117/500\n",
      "train_loss 0.0007414583318706218\n",
      "epochs 118/500\n",
      "train_loss 0.0007419250472780455\n",
      "epochs 119/500\n",
      "train_loss 0.0007400261379807772\n",
      "epochs 120/500\n",
      "train_loss 0.0007409823885134375\n",
      "epochs 121/500\n",
      "train_loss 0.0007360831555635294\n",
      "epochs 122/500\n",
      "train_loss 0.0007384272605757332\n",
      "epochs 123/500\n",
      "train_loss 0.0007351096622134139\n",
      "epochs 124/500\n",
      "train_loss 0.0007337581255296581\n",
      "epochs 125/500\n",
      "train_loss 0.0007373139879440135\n",
      "epochs 126/500\n",
      "train_loss 0.0007325992031741057\n",
      "epochs 127/500\n",
      "train_loss 0.0007329720505230833\n",
      "epochs 128/500\n",
      "train_loss 0.0007326760357337097\n",
      "epochs 129/500\n",
      "train_loss 0.0007317124142798779\n",
      "epochs 130/500\n",
      "train_loss 0.0007321432714396018\n",
      "epochs 131/500\n",
      "train_loss 0.0007289746115883029\n",
      "epochs 132/500\n",
      "train_loss 0.000729749482134066\n",
      "epochs 133/500\n",
      "train_loss 0.0007281006438022015\n",
      "epochs 134/500\n",
      "train_loss 0.000728422872349716\n",
      "epochs 135/500\n",
      "train_loss 0.0007279745486076462\n",
      "epochs 136/500\n",
      "train_loss 0.0007263122942206321\n",
      "epochs 137/500\n",
      "train_loss 0.0007272001959538754\n",
      "epochs 138/500\n",
      "train_loss 0.0007250379211125316\n",
      "epochs 139/500\n",
      "train_loss 0.0007250000991356315\n",
      "epochs 140/500\n",
      "train_loss 0.0007226645085751096\n",
      "epochs 141/500\n",
      "train_loss 0.0007239380357410074\n",
      "epochs 142/500\n",
      "train_loss 0.0007221651518338727\n",
      "epochs 143/500\n",
      "train_loss 0.0007217951386595012\n",
      "epochs 144/500\n",
      "train_loss 0.0007200448796709704\n",
      "epochs 145/500\n",
      "train_loss 0.0007215823024459119\n",
      "epochs 146/500\n",
      "train_loss 0.0007186343213609588\n",
      "epochs 147/500\n",
      "train_loss 0.0007177067161043037\n",
      "epochs 148/500\n",
      "train_loss 0.000719232338316483\n",
      "epochs 149/500\n",
      "train_loss 0.0007193424268641029\n",
      "epochs 150/500\n",
      "train_loss 0.0007149903384169879\n",
      "epochs 151/500\n",
      "train_loss 0.0007157780229934547\n",
      "epochs 152/500\n",
      "train_loss 0.0007144306185741776\n",
      "epochs 153/500\n",
      "train_loss 0.0007137076899110603\n",
      "epochs 154/500\n",
      "train_loss 0.0007150600192913068\n",
      "epochs 155/500\n",
      "train_loss 0.0007139307679200144\n",
      "epochs 156/500\n",
      "train_loss 0.0007126306581718048\n",
      "epochs 157/500\n",
      "train_loss 0.0007117277364399068\n",
      "epochs 158/500\n",
      "train_loss 0.0007130059525773496\n",
      "epochs 159/500\n",
      "train_loss 0.0007091523132496049\n",
      "epochs 160/500\n",
      "train_loss 0.0007097126662509969\n",
      "epochs 161/500\n",
      "train_loss 0.000708664376447984\n",
      "epochs 162/500\n",
      "train_loss 0.0007086068235166054\n",
      "epochs 163/500\n",
      "train_loss 0.0007117304399094197\n",
      "epochs 164/500\n",
      "train_loss 0.0007071782509591\n",
      "epochs 165/500\n",
      "train_loss 0.0007063028670349487\n",
      "epochs 166/500\n",
      "train_loss 0.0007059352494253211\n",
      "epochs 167/500\n",
      "train_loss 0.0007035536092068431\n",
      "epochs 168/500\n",
      "train_loss 0.0007049715718594395\n",
      "epochs 169/500\n",
      "train_loss 0.0007047514937592021\n",
      "epochs 170/500\n",
      "train_loss 0.0007030842648362162\n",
      "epochs 171/500\n",
      "train_loss 0.0007022745125391595\n",
      "epochs 172/500\n",
      "train_loss 0.0007025354457597911\n",
      "epochs 173/500\n",
      "train_loss 0.0007019647895773205\n",
      "epochs 174/500\n",
      "train_loss 0.0007021331861412467\n",
      "epochs 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.0006992094412962208\n",
      "epochs 176/500\n",
      "train_loss 0.0007011136387089136\n",
      "epochs 177/500\n",
      "train_loss 0.0006996830463687501\n",
      "epochs 178/500\n",
      "train_loss 0.0006985824870556233\n",
      "epochs 179/500\n",
      "train_loss 0.000697773379244305\n",
      "epochs 180/500\n",
      "train_loss 0.0006975610618948297\n",
      "epochs 181/500\n",
      "train_loss 0.0006979457290307602\n",
      "epochs 182/500\n",
      "train_loss 0.0006962804600701937\n",
      "epochs 183/500\n",
      "train_loss 0.0006959247304279258\n",
      "epochs 184/500\n",
      "train_loss 0.0006967083683037154\n",
      "epochs 185/500\n",
      "train_loss 0.0006963509919563631\n",
      "epochs 186/500\n",
      "train_loss 0.0006961623235798847\n",
      "epochs 187/500\n",
      "train_loss 0.0006928697424081206\n",
      "epochs 188/500\n",
      "train_loss 0.0006929418541860642\n",
      "epochs 189/500\n",
      "train_loss 0.0006921801630009125\n",
      "epochs 190/500\n",
      "train_loss 0.000693150782647132\n",
      "epochs 191/500\n",
      "train_loss 0.000693160670540532\n",
      "epochs 192/500\n",
      "train_loss 0.0006914733813600791\n",
      "epochs 193/500\n",
      "train_loss 0.0006914401330568747\n",
      "epochs 194/500\n",
      "train_loss 0.000690685471450748\n",
      "epochs 195/500\n",
      "train_loss 0.000690504689146943\n",
      "epochs 196/500\n",
      "train_loss 0.0006915849479115748\n",
      "epochs 197/500\n",
      "train_loss 0.0006913188039695123\n",
      "epochs 198/500\n",
      "train_loss 0.0006915127087332963\n",
      "epochs 199/500\n",
      "train_loss 0.0006873760588442598\n",
      "epochs 200/500\n",
      "train_loss 0.0006876859117396736\n",
      "epochs 201/500\n",
      "train_loss 0.0006892087194264635\n",
      "epochs 202/500\n",
      "train_loss 0.0006883889880893318\n",
      "epochs 203/500\n",
      "train_loss 0.000687408119885505\n",
      "epochs 204/500\n",
      "train_loss 0.00068863428798703\n",
      "epochs 205/500\n",
      "train_loss 0.0006862983202320295\n",
      "epochs 206/500\n",
      "train_loss 0.0006842353618722233\n",
      "epochs 207/500\n",
      "train_loss 0.0006832867343743765\n",
      "epochs 208/500\n",
      "train_loss 0.0006854230347190103\n",
      "epochs 209/500\n",
      "train_loss 0.000682760241378059\n",
      "epochs 210/500\n",
      "train_loss 0.0006873927024693616\n",
      "epochs 211/500\n",
      "train_loss 0.0006831696189652037\n",
      "epochs 212/500\n",
      "train_loss 0.0006827628166115932\n",
      "epochs 213/500\n",
      "train_loss 0.0006833678842200099\n",
      "epochs 214/500\n",
      "train_loss 0.0006801864292123422\n",
      "epochs 215/500\n",
      "train_loss 0.0006840594175964207\n",
      "epochs 216/500\n",
      "train_loss 0.00067990283834262\n",
      "epochs 217/500\n",
      "train_loss 0.0006805660515696963\n",
      "epochs 218/500\n",
      "train_loss 0.000683797144384106\n",
      "epochs 219/500\n",
      "train_loss 0.000679755301061778\n",
      "epochs 220/500\n",
      "train_loss 0.0006801031448220821\n",
      "epochs 221/500\n",
      "train_loss 0.0006787413409965363\n",
      "epochs 222/500\n",
      "train_loss 0.0006780224546965198\n",
      "epochs 223/500\n",
      "train_loss 0.0006794715837474342\n",
      "epochs 224/500\n",
      "train_loss 0.0006774801776880052\n",
      "epochs 225/500\n",
      "train_loss 0.0006780554625100595\n",
      "epochs 226/500\n",
      "train_loss 0.0006794925210698165\n",
      "epochs 227/500\n",
      "train_loss 0.0006764537887141139\n",
      "epochs 228/500\n",
      "train_loss 0.0006757032624133941\n",
      "epochs 229/500\n",
      "train_loss 0.0006786662502628986\n",
      "epochs 230/500\n",
      "train_loss 0.000676996703805998\n",
      "epochs 231/500\n",
      "train_loss 0.0006755689157127188\n",
      "epochs 232/500\n",
      "train_loss 0.0006793676388008555\n",
      "epochs 233/500\n",
      "train_loss 0.0006730031050406023\n",
      "epochs 234/500\n",
      "train_loss 0.000675263631477808\n",
      "epochs 235/500\n",
      "train_loss 0.0006773966410235783\n",
      "epochs 236/500\n",
      "train_loss 0.0006734173243284009\n",
      "epochs 237/500\n",
      "train_loss 0.0006721568379977251\n",
      "epochs 238/500\n",
      "train_loss 0.0006753714519576814\n",
      "epochs 239/500\n",
      "train_loss 0.0006719050346978787\n",
      "epochs 240/500\n",
      "train_loss 0.0006735450328178759\n",
      "epochs 241/500\n",
      "train_loss 0.000674385865819639\n",
      "epochs 242/500\n",
      "train_loss 0.0006688752397367185\n",
      "epochs 243/500\n",
      "train_loss 0.000670677968706282\n",
      "epochs 244/500\n",
      "train_loss 0.000674229728516922\n",
      "epochs 245/500\n",
      "train_loss 0.0006698098310519558\n",
      "epochs 246/500\n",
      "train_loss 0.0006696460732070851\n",
      "epochs 247/500\n",
      "train_loss 0.000672788496762386\n",
      "epochs 248/500\n",
      "train_loss 0.0006685375378209108\n",
      "epochs 249/500\n",
      "train_loss 0.0006674492400377926\n",
      "epochs 250/500\n",
      "train_loss 0.0006702033828883702\n",
      "epochs 251/500\n",
      "train_loss 0.0006710316578736143\n",
      "epochs 252/500\n",
      "train_loss 0.0006685804392780281\n",
      "epochs 253/500\n",
      "train_loss 0.0006680907216812896\n",
      "epochs 254/500\n",
      "train_loss 0.0006705532699501181\n",
      "epochs 255/500\n",
      "train_loss 0.0006666957813532011\n",
      "epochs 256/500\n",
      "train_loss 0.0006675507445874022\n",
      "epochs 257/500\n",
      "train_loss 0.0006685329361468238\n",
      "epochs 258/500\n",
      "train_loss 0.0006684584354040859\n",
      "epochs 259/500\n",
      "train_loss 0.0006651130322219582\n",
      "epochs 260/500\n",
      "train_loss 0.000667065655969111\n",
      "epochs 261/500\n",
      "train_loss 0.0006695203084572139\n",
      "epochs 262/500\n",
      "train_loss 0.0006658527598930218\n",
      "epochs 263/500\n",
      "train_loss 0.0006643748711996013\n",
      "epochs 264/500\n",
      "train_loss 0.0006672695355156138\n",
      "epochs 265/500\n",
      "train_loss 0.0006677004726697465\n",
      "epochs 266/500\n",
      "train_loss 0.0006668604303229039\n",
      "epochs 267/500\n",
      "train_loss 0.0006667319736027423\n",
      "epochs 268/500\n",
      "train_loss 0.000666844401082676\n",
      "epochs 269/500\n",
      "train_loss 0.0006640580467013958\n",
      "epochs 270/500\n",
      "train_loss 0.0006642006458958534\n",
      "epochs 271/500\n",
      "train_loss 0.000663925410641922\n",
      "epochs 272/500\n",
      "train_loss 0.0006620340049090442\n",
      "epochs 273/500\n",
      "train_loss 0.0006656554076570091\n",
      "epochs 274/500\n",
      "train_loss 0.0006662175536741654\n",
      "epochs 275/500\n",
      "train_loss 0.0006627673115987096\n",
      "epochs 276/500\n",
      "train_loss 0.0006629559853945549\n",
      "epochs 277/500\n",
      "train_loss 0.0006636555066754121\n",
      "epochs 278/500\n",
      "train_loss 0.0006638476963650922\n",
      "epochs 279/500\n",
      "train_loss 0.0006644509205582998\n",
      "epochs 280/500\n",
      "train_loss 0.0006615770975989644\n",
      "epochs 281/500\n",
      "train_loss 0.000661146541093985\n",
      "epochs 282/500\n",
      "train_loss 0.0006616103485240249\n",
      "epochs 283/500\n",
      "train_loss 0.000659536187519815\n",
      "epochs 284/500\n",
      "train_loss 0.0006621273642183138\n",
      "epochs 285/500\n",
      "train_loss 0.000662313096315797\n",
      "epochs 286/500\n",
      "train_loss 0.0006590250302464327\n",
      "epochs 287/500\n",
      "train_loss 0.0006590616172724867\n",
      "epochs 288/500\n",
      "train_loss 0.000660255959497625\n",
      "epochs 289/500\n",
      "train_loss 0.0006610568144990816\n",
      "epochs 290/500\n",
      "train_loss 0.000660057554752262\n",
      "epochs 291/500\n",
      "train_loss 0.0006588556013657063\n",
      "epochs 292/500\n",
      "train_loss 0.0006586974583391266\n",
      "epochs 293/500\n",
      "train_loss 0.000657287486128166\n",
      "epochs 294/500\n",
      "train_loss 0.0006572280513208264\n",
      "epochs 295/500\n",
      "train_loss 0.0006567054428754727\n",
      "epochs 296/500\n",
      "train_loss 0.0006561408035965176\n",
      "epochs 297/500\n",
      "train_loss 0.0006611591592237261\n",
      "epochs 298/500\n",
      "train_loss 0.0006612788753603698\n",
      "epochs 299/500\n",
      "train_loss 0.0006557899848852217\n",
      "epochs 300/500\n",
      "train_loss 0.0006558007133305405\n",
      "epochs 301/500\n",
      "train_loss 0.0006556656771018384\n",
      "epochs 302/500\n",
      "train_loss 0.000655988457187585\n",
      "epochs 303/500\n",
      "train_loss 0.0006564689333625986\n",
      "epochs 304/500\n",
      "train_loss 0.0006556212496427689\n",
      "epochs 305/500\n",
      "train_loss 0.0006550100460130158\n",
      "epochs 306/500\n",
      "train_loss 0.000655047462030024\n",
      "epochs 307/500\n",
      "train_loss 0.0006541779021852423\n",
      "epochs 308/500\n",
      "train_loss 0.0006535614532904067\n",
      "epochs 309/500\n",
      "train_loss 0.0006573737977599276\n",
      "epochs 310/500\n",
      "train_loss 0.0006536422636195954\n",
      "epochs 311/500\n",
      "train_loss 0.0006542447323918665\n",
      "epochs 312/500\n",
      "train_loss 0.0006512837066180357\n",
      "epochs 313/500\n",
      "train_loss 0.0006539159606729412\n",
      "epochs 314/500\n",
      "train_loss 0.0006551354017414107\n",
      "epochs 315/500\n",
      "train_loss 0.0006519166343242591\n",
      "epochs 316/500\n",
      "train_loss 0.0006521997058271651\n",
      "epochs 317/500\n",
      "train_loss 0.0006542632065502869\n",
      "epochs 318/500\n",
      "train_loss 0.0006518278208668361\n",
      "epochs 319/500\n",
      "train_loss 0.0006522139727987355\n",
      "epochs 320/500\n",
      "train_loss 0.0006524366078321829\n",
      "epochs 321/500\n",
      "train_loss 0.0006494437733211962\n",
      "epochs 322/500\n",
      "train_loss 0.0006510240104032685\n",
      "epochs 323/500\n",
      "train_loss 0.0006520046126997232\n",
      "epochs 324/500\n",
      "train_loss 0.0006513768097714802\n",
      "epochs 325/500\n",
      "train_loss 0.0006507758464466094\n",
      "epochs 326/500\n",
      "train_loss 0.0006531956054254324\n",
      "epochs 327/500\n",
      "train_loss 0.0006500832650825177\n",
      "epochs 328/500\n",
      "train_loss 0.0006513139355638159\n",
      "epochs 329/500\n",
      "train_loss 0.0006541633131118835\n",
      "epochs 330/500\n",
      "train_loss 0.0006489531864352417\n",
      "epochs 331/500\n",
      "train_loss 0.0006496452118137496\n",
      "epochs 332/500\n",
      "train_loss 0.0006522627907954711\n",
      "epochs 333/500\n",
      "train_loss 0.0006506252562199103\n",
      "epochs 334/500\n",
      "train_loss 0.0006491075217474691\n",
      "epochs 335/500\n",
      "train_loss 0.0006507050417451501\n",
      "epochs 336/500\n",
      "train_loss 0.0006488051012131285\n",
      "epochs 337/500\n",
      "train_loss 0.0006493792159951639\n",
      "epochs 338/500\n",
      "train_loss 0.0006478155699328858\n",
      "epochs 339/500\n",
      "train_loss 0.0006513874326299871\n",
      "epochs 340/500\n",
      "train_loss 0.0006485381736596634\n",
      "epochs 341/500\n",
      "train_loss 0.0006490437265571037\n",
      "epochs 342/500\n",
      "train_loss 0.0006493765889444846\n",
      "epochs 343/500\n",
      "train_loss 0.0006482006645254019\n",
      "epochs 344/500\n",
      "train_loss 0.0006493177393655922\n",
      "epochs 345/500\n",
      "train_loss 0.000649044898078934\n",
      "epochs 346/500\n",
      "train_loss 0.0006478696184148399\n",
      "epochs 347/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.0006488108081760727\n",
      "epochs 348/500\n",
      "train_loss 0.0006473047018243348\n",
      "epochs 349/500\n",
      "train_loss 0.0006462638283596045\n",
      "epochs 350/500\n",
      "train_loss 0.0006490059550613528\n",
      "epochs 351/500\n",
      "train_loss 0.0006462451000104634\n",
      "epochs 352/500\n",
      "train_loss 0.0006468521045272369\n",
      "epochs 353/500\n",
      "train_loss 0.0006475473997820918\n",
      "epochs 354/500\n",
      "train_loss 0.0006475988601078621\n",
      "epochs 355/500\n",
      "train_loss 0.0006495839868447561\n",
      "epochs 356/500\n",
      "train_loss 0.0006454800314320578\n",
      "epochs 357/500\n",
      "train_loss 0.0006456845624286495\n",
      "epochs 358/500\n",
      "train_loss 0.0006451255388754388\n",
      "epochs 359/500\n",
      "train_loss 0.0006474962814327884\n",
      "epochs 360/500\n",
      "train_loss 0.0006465268752475136\n",
      "epochs 361/500\n",
      "train_loss 0.0006444425031591868\n",
      "epochs 362/500\n",
      "train_loss 0.0006462997431335372\n",
      "epochs 363/500\n",
      "train_loss 0.0006442318140449419\n",
      "epochs 364/500\n",
      "train_loss 0.0006442714215886473\n",
      "epochs 365/500\n",
      "train_loss 0.0006492053721093194\n",
      "epochs 366/500\n",
      "train_loss 0.0006423268556393413\n",
      "epochs 367/500\n",
      "train_loss 0.0006437553989074402\n",
      "epochs 368/500\n",
      "train_loss 0.0006419792885905626\n",
      "epochs 369/500\n",
      "train_loss 0.0006431147143903149\n",
      "epochs 370/500\n",
      "train_loss 0.0006423756559912643\n",
      "epochs 371/500\n",
      "train_loss 0.0006443656159658732\n",
      "epochs 372/500\n",
      "train_loss 0.0006416080545955346\n",
      "epochs 373/500\n",
      "train_loss 0.0006426624211032717\n",
      "epochs 374/500\n",
      "train_loss 0.0006425973780039774\n",
      "epochs 375/500\n",
      "train_loss 0.000640353342082222\n",
      "epochs 376/500\n",
      "train_loss 0.000640536599767506\n",
      "epochs 377/500\n",
      "train_loss 0.0006423847790156897\n",
      "epochs 378/500\n",
      "train_loss 0.0006401492075753281\n",
      "epochs 379/500\n",
      "train_loss 0.0006404882632211361\n",
      "epochs 380/500\n",
      "train_loss 0.0006424553845001593\n",
      "epochs 381/500\n",
      "train_loss 0.0006393340768821137\n",
      "epochs 382/500\n",
      "train_loss 0.0006405845078793131\n",
      "epochs 383/500\n",
      "train_loss 0.0006418993719144522\n",
      "epochs 384/500\n",
      "train_loss 0.0006386486384576416\n",
      "epochs 385/500\n",
      "train_loss 0.0006384940719493719\n",
      "epochs 386/500\n",
      "train_loss 0.0006397595351435155\n",
      "epochs 387/500\n",
      "train_loss 0.0006401970954501856\n",
      "epochs 388/500\n",
      "train_loss 0.0006428136325434361\n",
      "epochs 389/500\n",
      "train_loss 0.0006378342448436334\n",
      "epochs 390/500\n",
      "train_loss 0.0006385022612619907\n",
      "epochs 391/500\n",
      "train_loss 0.0006369700144954666\n",
      "epochs 392/500\n",
      "train_loss 0.0006384293944231176\n",
      "epochs 393/500\n",
      "train_loss 0.0006403461084459568\n",
      "epochs 394/500\n",
      "train_loss 0.0006364995654487542\n",
      "epochs 395/500\n",
      "train_loss 0.0006375207560018417\n",
      "epochs 396/500\n",
      "train_loss 0.0006399952161847099\n",
      "epochs 397/500\n",
      "train_loss 0.0006368756894571982\n",
      "epochs 398/500\n",
      "train_loss 0.0006376118571663052\n",
      "epochs 399/500\n",
      "train_loss 0.0006394189483290896\n",
      "epochs 400/500\n",
      "train_loss 0.0006369758925329984\n",
      "epochs 401/500\n",
      "train_loss 0.000637059323226323\n",
      "epochs 402/500\n",
      "train_loss 0.0006393055690297187\n",
      "epochs 403/500\n",
      "train_loss 0.0006367522889065469\n",
      "epochs 404/500\n",
      "train_loss 0.0006352650169624555\n",
      "epochs 405/500\n",
      "train_loss 0.0006380299205836701\n",
      "epochs 406/500\n",
      "train_loss 0.0006361258174456571\n",
      "epochs 407/500\n",
      "train_loss 0.0006387317791527358\n",
      "epochs 408/500\n",
      "train_loss 0.0006365127400906683\n",
      "epochs 409/500\n",
      "train_loss 0.00063645165858182\n",
      "epochs 410/500\n",
      "train_loss 0.000635769984050111\n",
      "epochs 411/500\n",
      "train_loss 0.0006382570903915689\n",
      "epochs 412/500\n",
      "train_loss 0.0006372210805907232\n",
      "epochs 413/500\n",
      "train_loss 0.0006380090181685905\n",
      "epochs 414/500\n",
      "train_loss 0.0006349527410819893\n",
      "epochs 415/500\n",
      "train_loss 0.0006349321460018005\n",
      "epochs 416/500\n",
      "train_loss 0.0006349567189198831\n",
      "epochs 417/500\n",
      "train_loss 0.000636989176570921\n",
      "epochs 418/500\n",
      "train_loss 0.0006374246880756244\n",
      "epochs 419/500\n",
      "train_loss 0.0006340021754954662\n",
      "epochs 420/500\n",
      "train_loss 0.0006322579335709818\n",
      "epochs 421/500\n",
      "train_loss 0.0006354070124260259\n",
      "epochs 422/500\n",
      "train_loss 0.0006344122382891338\n",
      "epochs 423/500\n",
      "train_loss 0.000633530554512929\n",
      "epochs 424/500\n",
      "train_loss 0.0006361997718986371\n",
      "epochs 425/500\n",
      "train_loss 0.0006338543714939306\n",
      "epochs 426/500\n",
      "train_loss 0.000634035035885394\n",
      "epochs 427/500\n",
      "train_loss 0.000635538812824728\n",
      "epochs 428/500\n",
      "train_loss 0.0006329603405894856\n",
      "epochs 429/500\n",
      "train_loss 0.0006316481000088336\n",
      "epochs 430/500\n",
      "train_loss 0.000634689719458544\n",
      "epochs 431/500\n",
      "train_loss 0.0006344865094477044\n",
      "epochs 432/500\n",
      "train_loss 0.0006320994725278918\n",
      "epochs 433/500\n",
      "train_loss 0.0006320566571167879\n",
      "epochs 434/500\n",
      "train_loss 0.0006324263798352111\n",
      "epochs 435/500\n",
      "train_loss 0.0006312891378870846\n",
      "epochs 436/500\n",
      "train_loss 0.0006344681424608644\n",
      "epochs 437/500\n",
      "train_loss 0.0006319514590560417\n",
      "epochs 438/500\n",
      "train_loss 0.0006323747073398008\n",
      "epochs 439/500\n",
      "train_loss 0.0006314729291317636\n",
      "epochs 440/500\n",
      "train_loss 0.000632917035959197\n",
      "epochs 441/500\n",
      "train_loss 0.0006316050026538811\n",
      "epochs 442/500\n",
      "train_loss 0.0006318965464064644\n",
      "epochs 443/500\n",
      "train_loss 0.0006318960217989338\n",
      "epochs 444/500\n",
      "train_loss 0.0006333160241269\n",
      "epochs 445/500\n",
      "train_loss 0.0006313804031267168\n",
      "epochs 446/500\n",
      "train_loss 0.0006323522164521934\n",
      "epochs 447/500\n",
      "train_loss 0.0006313499748968446\n",
      "epochs 448/500\n",
      "train_loss 0.0006330790840188594\n",
      "epochs 449/500\n",
      "train_loss 0.0006280125548625621\n",
      "epochs 450/500\n",
      "train_loss 0.0006304987663145235\n",
      "epochs 451/500\n",
      "train_loss 0.0006314014691428208\n",
      "epochs 452/500\n",
      "train_loss 0.0006292112326349389\n",
      "epochs 453/500\n",
      "train_loss 0.0006296261306427374\n",
      "epochs 454/500\n",
      "train_loss 0.000629484384565756\n",
      "epochs 455/500\n",
      "train_loss 0.0006300688343292584\n",
      "epochs 456/500\n",
      "train_loss 0.0006364230913781501\n",
      "epochs 457/500\n",
      "train_loss 0.0006327566935662712\n",
      "epochs 458/500\n",
      "train_loss 0.00062966715566408\n",
      "epochs 459/500\n",
      "train_loss 0.0006290866734209585\n",
      "epochs 460/500\n",
      "train_loss 0.0006301549430304679\n",
      "epochs 461/500\n",
      "train_loss 0.0006308695564646707\n",
      "epochs 462/500\n",
      "train_loss 0.000627563025116071\n",
      "epochs 463/500\n",
      "train_loss 0.0006311214481922929\n",
      "epochs 464/500\n",
      "train_loss 0.0006319517388151973\n",
      "epochs 465/500\n",
      "train_loss 0.0006278535608265249\n",
      "epochs 466/500\n",
      "train_loss 0.0006288033323639861\n",
      "epochs 467/500\n",
      "train_loss 0.000628897271118453\n",
      "epochs 468/500\n",
      "train_loss 0.000629455938445742\n",
      "epochs 469/500\n",
      "train_loss 0.0006304196157538061\n",
      "epochs 470/500\n",
      "train_loss 0.0006290045673390435\n",
      "epochs 471/500\n",
      "train_loss 0.0006288119831891926\n",
      "epochs 472/500\n",
      "train_loss 0.0006293134136920546\n",
      "epochs 473/500\n",
      "train_loss 0.0006299858340897847\n",
      "epochs 474/500\n",
      "train_loss 0.0006285793463476811\n",
      "epochs 475/500\n",
      "train_loss 0.0006284474435097302\n",
      "epochs 476/500\n",
      "train_loss 0.0006281687141039683\n",
      "epochs 477/500\n",
      "train_loss 0.0006269042467660019\n",
      "epochs 478/500\n",
      "train_loss 0.0006276391806363188\n",
      "epochs 479/500\n",
      "train_loss 0.000627708145928005\n",
      "epochs 480/500\n",
      "train_loss 0.0006286356091188912\n",
      "epochs 481/500\n",
      "train_loss 0.0006280288632129692\n",
      "epochs 482/500\n",
      "train_loss 0.0006281961125894074\n",
      "epochs 483/500\n",
      "train_loss 0.0006272712658031378\n",
      "epochs 484/500\n",
      "train_loss 0.0006295468079523011\n",
      "epochs 485/500\n",
      "train_loss 0.0006290816667638434\n",
      "epochs 486/500\n",
      "train_loss 0.0006258560228039887\n",
      "epochs 487/500\n",
      "train_loss 0.0006252386191390362\n",
      "epochs 488/500\n",
      "train_loss 0.0006268393748111287\n",
      "epochs 489/500\n",
      "train_loss 0.0006265876950899309\n",
      "epochs 490/500\n",
      "train_loss 0.0006286388846666004\n",
      "epochs 491/500\n",
      "train_loss 0.0006268899409178732\n",
      "epochs 492/500\n",
      "train_loss 0.0006277759115042707\n",
      "epochs 493/500\n",
      "train_loss 0.0006261793955693942\n",
      "epochs 494/500\n",
      "train_loss 0.0006263053883664076\n",
      "epochs 495/500\n",
      "train_loss 0.0006269716562543169\n",
      "epochs 496/500\n",
      "train_loss 0.0006272069705066199\n",
      "epochs 497/500\n",
      "train_loss 0.000625498826892964\n",
      "epochs 498/500\n",
      "train_loss 0.0006256056472546665\n",
      "epochs 499/500\n",
      "train_loss 0.0006274766589118672\n",
      "epochs 500/500\n",
      "train_loss 0.0006267933335110542\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    print('epochs {}/{}'.format(epoch+1,epochs))\n",
    "    Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ffb580b5490>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses,label='train_loss')\n",
    "plt.title('MSE Loss')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "batch_size = 1\n",
    "\n",
    "def Predictions():\n",
    "    model.eval()\n",
    "    for i in range(len(X)):\n",
    "        pred = model(torch.from_numpy(X[i]).unsqueeze(0)).float()\n",
    "        preds.append(pred.detach().numpy().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(preds)\n",
    "predictions.index = data[3:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2018-01-01 00:45:00</td>\n",
       "      <td>0.236042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>0.236042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-01 01:15:00</td>\n",
       "      <td>0.236042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-01 01:30:00</td>\n",
       "      <td>0.236042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-01 01:45:00</td>\n",
       "      <td>0.236042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 22:45:00</td>\n",
       "      <td>0.298252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 23:00:00</td>\n",
       "      <td>0.297140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 23:15:00</td>\n",
       "      <td>0.295123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 23:30:00</td>\n",
       "      <td>0.298988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 23:45:00</td>\n",
       "      <td>0.296867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "Time                         \n",
       "2018-01-01 00:45:00  0.236042\n",
       "2018-01-01 01:00:00  0.236042\n",
       "2018-01-01 01:15:00  0.236042\n",
       "2018-01-01 01:30:00  0.236042\n",
       "2018-01-01 01:45:00  0.236042\n",
       "...                       ...\n",
       "2018-12-31 22:45:00  0.298252\n",
       "2018-12-31 23:00:00  0.297140\n",
       "2018-12-31 23:15:00  0.295123\n",
       "2018-12-31 23:30:00  0.298988\n",
       "2018-12-31 23:45:00  0.296867\n",
       "\n",
       "[1821 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('predictions_CNN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score\n",
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_CNN = MSE(Y, predictions)\n",
    "RMSE_CNN = MSE(Y, predictions)**(0.5)\n",
    "MAE_CNN = MAE(Y, predictions)\n",
    "MAPE_CNN = MAPE(Y, predictions)\n",
    "R2_CNN = r2_score(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metric_CNN = {\n",
    "    'MSE_CNN':MSE_CNN,\n",
    "    'RMSE_CNN':RMSE_CNN,\n",
    "    'MAE_CNN':MAE_CNN,\n",
    "    'MAPE_CNN':MAPE_CNN,\n",
    "    'R_Squared_CNN':R2_CNN\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE_CNN': 0.000605432580241261,\n",
       " 'RMSE_CNN': 0.02460553962507754,\n",
       " 'MAE_CNN': 0.011346047667968939,\n",
       " 'MAPE_CNN': 5.259139017322088,\n",
       " 'R_Squared_CNN': 0.9603470071856154}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Metric_CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
